{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (20.0, 18.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frames(file):\n",
    "    \"\"\"function to extract the frames in which the dice are settled \n",
    "    after rolling.\n",
    "    \n",
    "    imput: list of file names of the videos\n",
    "    output: list of captured frames\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list to store the captured frames from the video\n",
    "    captured_frames = []\n",
    "\n",
    "    \n",
    "    cap = cv2.VideoCapture(file)\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    n_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    img_list = []\n",
    "    while cap.isOpened():\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        frame_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate/2.0) == 0):\n",
    "            b,g,r = cv2.split(frame)\n",
    "            img = cv2.merge((b,g,r))\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img_list.append(gray_image)\n",
    "    cap.release()\n",
    "\n",
    "    frame_diff_list = []\n",
    "    # calculating the frame difference between consecutive frames\n",
    "    for i in range(1,len(img_list)):\n",
    "        frame_diff = cv2.absdiff(img_list[i],img_list[i-1])\n",
    "        frame_diff = cv2.GaussianBlur(frame_diff,(3,3),0)\n",
    "        frame_diff = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        frame_diff_list.append(cv2.countNonZero(frame_diff))\n",
    "\n",
    "    min_idx = np.argmin(frame_diff_list)\n",
    "    if len(frame_diff_list) > 6 and min_idx > int(len(frame_diff_list)*0.8):\n",
    "        min_idx = np.argmin(frame_diff_list[:-2])\n",
    "    # storing the frame with the least consecutive frame difference for further processing\n",
    "    captured_frames.append(img_list[min_idx+1])\n",
    "    return captured_frames\n",
    "\n",
    "def detect_pips_and_locations(captured_frames):\n",
    "    \"\"\" function to detect the pips on the top face\n",
    "    and location of each die \n",
    "    \n",
    "    input: list of frames\n",
    "    output: plot of each frame with detected pips and number of pips\n",
    "    \"\"\"\n",
    "    \n",
    "    for f in captured_frames:\n",
    "        gray_image = f\n",
    "        x_range1 = int(gray_image.shape[0]*0.06)\n",
    "        x_range2 = int(gray_image.shape[0]*0.91)\n",
    "        y_range1 = int(gray_image.shape[1]*0.05)\n",
    "        y_range2 = int(gray_image.shape[1]*0.95)\n",
    "\n",
    "        # cropping out the outer border\n",
    "        gray_image[:,0:y_range1] = 0.0\n",
    "        gray_image[:,y_range2:] = 0.0\n",
    "        gray_image[:x_range1,:] = 0.0\n",
    "        gray_image[x_range2:,:] = 0.0\n",
    "\n",
    "        plt.figure(figsize=(20,18))\n",
    "\n",
    "        # setting the parameters for the blob_detection function of OpenCV\n",
    "        min_threshold = 50                     \n",
    "        max_threshold = 200                     \n",
    "        min_area = 100                          \n",
    "        max_area = 250\n",
    "        min_circularity = .4\n",
    "        min_inertia_ratio = .4\n",
    "\n",
    "        params = cv2.SimpleBlobDetector_Params()  \n",
    "        params.filterByArea = True\n",
    "        params.filterByCircularity = True\n",
    "        params.filterByInertia = True\n",
    "        params.minThreshold = min_threshold\n",
    "        params.maxThreshold = max_threshold\n",
    "        params.minArea = min_area\n",
    "        params.maxArea = max_area\n",
    "        params.minCircularity = min_circularity\n",
    "        params.minInertiaRatio = min_inertia_ratio\n",
    "\n",
    "        detector = cv2.SimpleBlobDetector_create(params) # create a blob detector object.\n",
    "        keypoints = detector.detect(gray_image) # keypoints is a list containing the detected blobs.\n",
    "        inv_image = cv2.bitwise_not(gray_image)\n",
    "        keypoints2 = detector.detect(inv_image)\n",
    "        im_with_keypoints = cv2.drawKeypoints(gray_image, keypoints+keypoints2, np.array([]), (0, 0, 255),\n",
    "                                              cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        thresh = 39\n",
    "        X = np.array([list(i.pt) for i in keypoints+keypoints2])\n",
    "\n",
    "        # using hierarchical clustering to cluster the pips so that the pips belonging to\n",
    "        # different groups could be grouped separately\n",
    "        if len(X) > 0:\n",
    "            clusters = hcluster.fclusterdata(X, thresh, criterion=\"distance\")\n",
    "            cluster_no = [np.sum(clusters==i) for i in clusters]\n",
    "            num_dict = {np.where(clusters == i)[0][0]:np.sum(clusters==i) for i in np.unique(clusters)}\n",
    "            key_map = {i:{np.sum(clusters==i):[X[np.where(np.array(clusters) == i)[0]]]} for i in np.unique(clusters)}\n",
    "            for i,v in key_map.items():\n",
    "                for j, k in v.items():\n",
    "                    plt.text(k[0][0][0]+35, k[0][0][1]+18, s=str(j), fontsize=25, color='red')\n",
    "            # plotting\n",
    "            plt.scatter(*np.transpose(X), c=clusters)\n",
    "            plt.axis(\"equal\")\n",
    "            title = \"threshold: %f, number of clusters: %d\" % (thresh, len(set(clusters)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_frames = capture_frames(\"Match2Piece1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captured_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_pips_and_locations(captured_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
